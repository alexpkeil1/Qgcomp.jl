var documenterSearchIndex = {"docs":
[{"location":"glm/#Introduction-to-Qgcomp.jl","page":"Generalized Linear Models","title":"Introduction to Qgcomp.jl","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Note: this is (copied directly from the qgcomp package in R, basic vignette).","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Qgcomp.jl is a module to implement g-computation for analyzing the effects of exposure mixtures. Quantile g-computation yields estimates of the effect of increasing all exposures by one quantile, simultaneously. This, it estimates a \"mixture effect\" useful in the study of exposure mixtures such as air pollution, diet, and water contamination.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Using terminology from methods developed for causal effect estimation, quantile  g-computation estimates the parameters of a marginal structural model that  characterizes the change in the expected potential outcome given a joint intervention on all exposures, possibly conditional on confounders. Under the assumptions of exchangeability, causal consistency, positivity, no interference, and correct model specification, this model yields a causal effect for an intervention on the mixture as a whole. While these assumptions may not be met exactly, they provide a useful road map for how to interpret the results of a qgcomp fit, and where efforts should be spent in terms of ensuring accurate model specification and selection of exposures that are sufficient to control co-pollutant confounding.","category":"page"},{"location":"glm/#The-model","page":"Generalized Linear Models","title":"The model","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Say we have an outcome Y, some exposures mathbbX and possibly some other covariates (e.g. potential confounders) denoted by mathbbZ.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"The basic model of quantile g-computation is a joint marginal structural model given by","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"mathbbE(Y^mathbfX_q  mathbfZpsieta) = g(psi_0 + psi_1 S_q +  mathbfeta Z)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"where g(cdot) is a link function in a generalized linear model (e.g. the inverse logit function in the case of a logistic model for the probability that Y=1), psi_0 is the model intercept, mathbfeta is a set of model coefficients for the covariates and S_q is an \"index\" that represents a joint value of exposures. Quantile g-computation (by default) transforms all exposures mathbfX into mathbfX_q, which are \"scores\" taking on discrete values 0,1,2,etc. representing a categorical \"bin\" of exposure. By default, there are four bins with evenly spaced quantile cutpoints for each exposure, so X_q=0 means that X was below the observed 25th percentile for that exposure. The index S_q represents all exposures being set to the same value (again, by default, discrete values 0,1,2,3). Thus, the parameter psi_1 quantifies the expected change in the outcome, given a one quantile increase in all exposures simultaneously, possibly adjusted for mathbfZ. ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"There are nuances to this particular model form that are available in the qgcomp package which will be explored below. There exists one special case of quantile g-computation that leads to fast fitting: linear/additive exposure effects. Here we simulate \"pre-quantized\" data where the exposures X_1 X_2 X_3 can only take on values of 0,1,2,3 in equal proportions. The model underlying the outcomes is given by the linear regression:","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"mathbbE(Y  mathbfXbeta) = beta_0 + beta_1 X_1 + beta_2 X_2 + beta_3 X_3","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"with the true values of beta_0=0 beta_1 =025 beta_2 =-01 beta_3=005, and X_1 is strongly positively correlated with X_2 (rho=095) and negatively correlated with X_3 (rho=-03). In this simple setting, the parameter psi_1 will equal the sum of the beta coefficients (0.2). Here we see that qgcomp estimates a value very close to 0.2 (as we increase sample size, the estimated value will be expected to become increasingly close to 0.2).","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"#cd(\"Qgcomp.jl/docs/src/fig/\")\n\nusing Qgcomp, DataFrames, Random, StatsBase, GLM, StatsModels\n\n# a function to generate quantized data with a specific correlation structure\nfunction genxq(rng, n, corr=(0.95, -0.3), q=4)\n    x = rand(rng, n, length(corr)+1)\n    props = abs.(corr)\n    ns = floor.(Int, n .* props)\n    nidx = [setdiff(1:n, sample(rng, 1:n, nsi, replace=false)) for nsi in ns]\n    for (j,c) in enumerate(corr)\n        x[:,j+1] .= x[:,1]\n        x[nidx[j],j+1] .= sample(rng, x[nidx[j],1], length(nidx[j]), replace=false)\n        if c < 0\n            x[:,j+1] .= 1.0 .- x[:,j+1]\n        end\n    end\n    xq, _ = Qgcomp.get_xq(x, q)\n    x, xq\nend\n\n# generate some data under a linear model with \"quantized\" exposures\n    rng = Xoshiro(321)\n    n = 1000\n    X, Xq = genxq(rng, 1000, (0.95, -0.3))\n    y = randn(rng, n) + Xq * [0.25, -0.1, 0.05]\n    lindata = DataFrame(hcat(y, X), [:y, :x1, :x2, :x3])\n\n    # check correlations\n    println(cor(Xq))\n\n    # fit model\n    qgcomp_glm_noboot(@formula(y~x1+x2+x3), lindata, [\"x1\", \"x2\", \"x3\"], 4, Normal())","category":"page"},{"location":"glm/#How-to-use-the-Qgcomp-module","page":"Generalized Linear Models","title":"How to use the Qgcomp module","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Here we use a running example from the metals dataset (part of the qgcomp package in R) to demonstrate some features of the package and method. ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Namely, the examples below demonstrate use of the package for:","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Fast estimation of exposure effects under a linear model for quantized exposures for continuous (normal) outcomes\nEstimating conditional and marginal odds/risk ratios of a mixture effect for binary outcomes\nAdjusting for non-exposure covariates when estimating effects of the mixture\nAllowing non-linear and non-homogeneous effects of individual exposures and the mixture as a whole by including product terms\nUsing qgcomp to fit a time-to-event model to estimate conditional and marginal hazard ratios for the exposure mixture","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"For analogous approaches to estimating exposure mixture effects, illustrative examples can be seen in the gQWS package help files, which implements weighted quantile sum (WQS) regression, and at https://jenfb.github.io/bkmr/overview.html, which describes Bayesian kernel machine regression.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"The metals dataset from the package qgcomp, comprises a set of simulated well water exposures and two health outcomes (one continuous, one binary/time-to-event). The exposures are transformed to have mean = 0.0, standard deviation = 1.0. The data are used throughout to demonstrate usage and features of the qgcomp package.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"using RData\ntf = tempname() * \".RData\"\ndownload(\"https://github.com/alexpkeil1/qgcomp/raw/refs/heads/main/data/metals.RData\", tf)\nmetals = load(tf)[\"metals\"]\nprintln(metals[1:10,:])\n\n# we save the names of the mixture variables in the variable \"Xnm\"\nXnm = [\n    \"arsenic\",\"barium\",\"cadmium\",\"calcium\",\"chromium\",\"copper\",\n    \"iron\",\"lead\",\"magnesium\",\"manganese\",\"mercury\",\"selenium\",\"silver\",\n    \"sodium\",\"zinc\"\n\n];\n\ncovars = [\"nitrate\",\"nitrite\",\"sulfate\",\"ph\", \"total_alkalinity\",\"total_hardness\"];\n","category":"page"},{"location":"glm/#Example-1:-linear-model","page":"Generalized Linear Models","title":"Example 1: linear model","text":"","category":"section"},{"location":"glm/#Qgcomp.qgcomp_glm_noboot","page":"Generalized Linear Models","title":"Qgcomp.qgcomp_glm_noboot","text":"using Qgcomp, DataFrames, StatsModels\n\nx1 = rand(100, 3)\nx = rand(100, 3)\nz = rand(100, 3)\nxq, _ = Qgcomp.get_xq(x, 4)\ny = randn(100) + xq * [.1, 0.05, 0]\ndata = DataFrame(hcat(y,x,z), [:y, :x1, :x2, :x3, :z1, :z2, :z3])\nform = @formula(y~x1+x2+x3+z1+z2+z3)\nform_noint = @formula(y~-1+x1+x2+x3+z1+z2+z3)\nexpnms = [:x1, :x2, :x3]\n\nm = qgcomp_glm_noboot(form, data, expnms, 4, Normal())\nm = qgcomp_glm_noboot(form_noint, data, expnms, 4, Normal())\nfitted(m)\naic(m)\naicc(m)\nbic(m)\nloglikelihood(m)\n\n\n\n\n\n","category":"function"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"# Example 1: linear model\n# Run the model and save the results \"qc_fit\"\nf = @formula(y~1+a+b)\nff = FormulaTerm(f.lhs, (Term.(Symbol.(Xnm))...,))\nqgcomp_glm_noboot(ff, metals[:,vcat(Xnm, \"y\")], Xnm, 4, Normal()) # run once to compile\n@time qc_fit = qgcomp_glm_noboot(ff, metals[:,vcat(Xnm, \"y\")], Xnm, 4, Normal())\n\n#  0.001750 seconds (49.98 k allocations: 2.679 MiB)\n# contrasting other methods with computational speed\n# WQS regression (v3.0.1 of gWQS package in R)\n#system.time(wqs.fit = gWQS::gwqs(y~wqs,mix_name=Xnm, data=metals[:,vcat(Xnm, \"y\")], Normal(), 4))\n#   user  system elapsed \n# 35.775   0.124  36.114 \n\n# Bayesian kernel machine regression (note that the number of iterations here would \n#  need to be >5,000, at minimum, so this underestimates the run time by a factor\n#  of 50+\n#system.time(bkmr.fit = kmbayes(y=metals$y, Z=metals[,Xnm], family=\"gaussian\", iter=100))\n#   user  system elapsed \n# 81.644   4.194  86.520 ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"First note that qgcomp can be very fast relative to competing methods (with their example times given from single runs from a laptop). ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"One advantage of quantile g-computation over other methods that estimate  \"mixture effects\" (the effect of changing all exposures at once), is that it  is very computationally efficient. Contrasting methods such as WQS (gWQS  package) and Bayesian Kernel Machine regression (bkmr package),  quantile g-computation can provide results many orders of magnitude faster. For example, the example above ran 3000X faster for quantile g-computation versus WQS regression, and we estimate the speedup would be several hundred thousand times versus Bayesian kernel machine regression. ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"The speed relies on an efficient method to fit qgcomp when exposures are added additively to the model. When exposures are added using non-linear terms or non-additive terms (see below for examples), then qgcomp will be slower but often still faster than competetive approaches.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Quantile g-computation yields fixed weights in the estimation procedure, similar to WQS regression. However, note that the weights from qgcomp_glm_noboot  can be negative or positive. When all effects are linear and in the same  direction (\"directional homogeneity\"), quantile g-computation is equivalent to  weighted quantile sum regression in large samples.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"The overall mixture effect from quantile g-computation (psi1) is interpreted as  the effect on the outcome of increasing every exposure by one quantile, possibly conditional on covariates. Given the overall exposure effect, the weights are considered fixed and so do not have confidence intervals or p-values.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"qc_fit","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Now let\"s take a brief look under the hood. qgcomp works in steps. First, the exposure variables are \"quantized\" or turned into score variables based on the total number of quantiles from the parameter q. You can access these via the qx object from the qgcomp fit object.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"# quantized data\nprintln(qc_fit.data[1:10,:])","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"You can re-fit a linear model using these quantized exposures. This is the \"underlying model\" of a qgcomp fit.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"# regression with quantized data\nnewfit = lm(@formula(y ~ arsenic + barium + cadmium + calcium + chromium + copper + \n    iron + lead + magnesium + manganese + mercury + selenium + \n    silver + sodium + zinc), qc_fit.data)\nprintln(newfit)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Here you can see that, for a GLM in which all quantized exposures enter linearly and additively into the underlying model, the overall effect from qgcomp is simply the sum of the adjusted coefficients from the underlying model. ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"println(sum(coef(newfit)[2:end])) # sum of all coefficients excluding intercept and confounders, if any\nprintln(qc_fit.fit[1][2])   # overall effect and intercept from qgcomp fit","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"This equality is why we can fit qgcomp so efficiently under such a model. This is a specific case, and qgcomp also allows deviations from linear/additive approaches via Monte-Carlo (here generally referred to as bootstrapping methods) and estimating-equation-based methods, which require a 2-stage approach. qgcomp can allow for non-linearity and non-additivity in the underlying model, as well as non-linearity in the overall model. These extensions are described in some of the following examples.","category":"page"},{"location":"glm/#Example-2:-conditional-odds-ratio,-marginal-odds-ratio-in-a-logistic-modela-name\"ex-logistic\"/a","page":"Generalized Linear Models","title":"Example 2: conditional odds ratio, marginal odds ratio in a logistic model<a name=\"ex-logistic\"></a>","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"This example introduces the use of a binary outcome in qgcomp via the  qgcomp_glm_noboot function, which yields a conditional odds ratio or the qgcomp_glm_boot, which yields a marginal odds ratio or risk/prevalence ratio. These will not equal each other when there are non-exposure covariates (e.g. confounders) included in the model because the odds ratio is not collapsible (both are still valid). Marginal parameters will yield estimates of the population average exposure effect, which is often of more interest due to better interpretability over conditional odds ratios. Further, odds ratios are not generally of interest when risk ratios can be validly estimated, so qgcomp_glm_boot will estimate the risk ratio by default for binary data (set rr=FALSE to allow estimation of ORs when using qgcomp_glm_boot).","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"f = @formula(disease_state~1+a+b)\nff = FormulaTerm(f.lhs, (GLM.Term.(Symbol.(Xnm))...,))\n\n# conditional odds ratio\nqc_fit2 = qgcomp_glm_noboot(ff, metals[:,vcat(Xnm, \"disease_state\")], Xnm, 4, Binomial())\n# marginal odds ratio\nqcboot_fit2 = qgcomp_glm_boot(Xoshiro(122),ff, metals[:,vcat(Xnm, \"disease_state\")], Xnm, 4, Binomial(), B=10)\n# marginal risk ratio\nqcboot_fit2b = qgcomp_glm_boot(Xoshiro(122),ff, metals[:,vcat(Xnm, \"disease_state\")], Xnm, 4, Binomial(), B=10, msmlink=LogLink())","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Compare a qgcomp_glm_noboot fit:","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"qc_fit2","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"with a qgcompglmboot fit:","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"qcboot_fit2","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"with a qgcompglmboot fit, where the risk/prevalence ratio is estimated, rather than the odds ratio:","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"qcboot_fit2b","category":"page"},{"location":"glm/#Example-3:-adjusting-for-covariates,-plotting-estimates","page":"Generalized Linear Models","title":"Example 3: adjusting for covariates, plotting estimates","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"In the following code we run a maternal age-adjusted linear model with qgcomp (family = Normal()). Further, we plot both the weights, as well as the mixture slope which yields overall model confidence bounds, representing the bounds that, for each value of the joint exposure are expected to contain the true regression line over 95% of trials (so-called 95% \"pointwise\" bounds for the regression line). The pointwise comparison bounds, denoted by error bars on the plot, represent comparisons of the expected difference in outcomes at each quantile, with reference  to a specific quantile (which can be specified by the user, as below). These pointwise bounds are similar to the bounds created in the bkmr package when plotting the overall effect of all exposures. The pointwise bounds can be obtained via the pointwisebound.boot function. To avoid confusion between \"pointwise regression\" and \"pointwise comparison\" bounds, the pointwise regression bounds are denoted as the \"model confidence band\" in the plots, since they yield estimates of the same type of bounds as the predict function in R when applied to linear model fits.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Note that the underlying regression model is on the exposure quantile \"scores\", which take on integer values 0, 1, ..., q-1. For plotting purposes (when plotting regression line results from qgcompglmboot), the quantile score is translated into a quantile (range = [0-1]). This is not a perfect correspondence, because the quantile g-computation model treats the  quantile score as a continuous variable, but the each quantile category spans a range of quantiles. For visualization, we fix the ends of the plot at the mid-points of the first and last quantile cut-point, so the range of the plot will change slightly if \"q\" is changed.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"using Plots\nqc_fit3 = qgcomp_glm_noboot(@formula(y ~ mage35 + arsenic + barium + cadmium + calcium + chloride + \n                           chromium + copper + iron + lead + magnesium + manganese + \n                           mercury + selenium + silver + sodium + zinc),\n                         metals, Xnm, 4, Normal())\nprintln(qc_fit3)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"weightplot(qc_fit3) ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"From the first plot we see weights from qgcomp_glm_noboot function, which include both positive and negative effect directions. When the weights are all on a single side of the null, these plots are easy to in interpret since the weight corresponds to the proportion of the overall effect from each exposure. WQS uses a constraint in the model to force all of the weights to be in the same direction - unfortunately such constraints lead to biased effect estimates. The qgcomp package takes a different approach and allows that \"weights\" might go in either direction, indicating that some exposures may beneficial, and some harmful, or there may be sampling variation due to using small or moderate sample sizes (or, more often, systematic bias such as unmeasured confounding). The \"weights\" in qgcomp correspond to the proportion of the overall effect when all of the exposures have effects in the same direction, but otherwise they correspond to the proportion of the effect in a particular direction, which may be small (or large) compared to the overall \"mixture\" effect. NOTE: the left and right sides of the  plot should not be compared with each other because the  length of the bars corresponds to the effect size only relative to other effects in the same direction. The darkness of the bars corresponds to the overall effect size - in this case the bars on the right (positive) side of the plot are darker because the overall \"mixture\" effect is positive. Thus, the shading allows one to make informal comparisons across the left and right sides: a large, darkly shaded bar indicates a larger independent effect than a large, lightly shaded bar.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"qcboot_fit3 = qgcomp_glm_boot(Xoshiro(122), @formula(y ~ mage35 + arsenic + barium + cadmium + calcium + chloride + \n                           chromium + copper + iron + lead + magnesium + manganese + \n                           mercury + selenium + silver + sodium + zinc), metals, Xnm, 4, Normal(), \n                           B=50)# B should be 200-500+ in practice\nprintln(qcboot_fit3)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"qcee_fit3 = qgcomp_glm_ee(@formula(y ~ mage35 + arsenic + barium + cadmium + calcium + chloride + \n                           chromium + copper + iron + lead + magnesium + manganese + \n                           mercury + selenium + silver + sodium + zinc), metals, Xnm, 4, Normal())\nprintln(qcee_fit3)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"We can change the referent category for pointwise comparisons via the referentindex parameter:","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"printbounds(bounds(qcee_fit3))","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"printbounds(bounds(qcboot_fit3))","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"responseplot(qcee_fit3, referentindex = 3, plots=[\"pointwise\", \"model\"]) ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"responseplot(qcboot_fit3, referentindex = 3, plots=[\"pointwise\", \"model\"]) ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Using qgcomp_glm_boot also allows us to assess linearity of the total exposure effect (the second plot). Similar output is available for WQS (gWQS package), though WQS results will generally be less interpretable when exposure effects are non-linear (see below how to do this with qgcomp_glm_boot and qgcomp_glm_ee). ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"The plot for the qcboot_fit3 object (using g-computation with bootstrap variance) gives predictions at the joint intervention levels of exposure. It also displays a smoothed (graphical) fit. ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Note that the uncertainty intervals given in the plot are directly accessible via the pointwisebound (pointwise comparison confidence intervals) and modelbound functions (confidence interval for the regression line):","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"printbounds(bounds(qcee_fit3, qcee_fit3.intvals, qcee_fit3.intvals[3]))","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"printbounds(bounds(qcboot_fit3))","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Because qgcomp estimates a joint effect of multiple exposures, we cannot, in general, assess model fit by overlaying predictions from the plots above with the data. Hence, it is useful to explore non-linearity by fitting models that allow for non-linear effects, as in the next example.","category":"page"},{"location":"glm/#Example-4:-non-linearity-(and-non-homogeneity)","page":"Generalized Linear Models","title":"Example 4: non-linearity (and non-homogeneity)","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"qgcomp (specifically qgcomp_*_boot and qgcomp_*_ee methods) addresses non-linearity in a way similar to standard parametric regression models, which lends itself to being able to leverage R language features for n-lin parametric models (or, more precisely, parametric models that deviate from a purely additive, linear function on the link function basis via the use of basis function representation of non-linear functions).  Here is an example where we use a feature of the R language for fitting models with interaction terms. We use y~. + .^2 as the model formula, which fits a model that allows for quadratic term for every predictor in the model. ","category":"page"},{"location":"glm/#Aside:-some-details-on-qgcomp-methods-for-non-linearity","page":"Generalized Linear Models","title":"Aside: some details on qgcomp methods for non-linearity","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Note that both qgcomp_*_boot (bootstrap) and qgcomp_*_ee (estimating equations) use standard methods for g-computation, whereas the qgcomp_*_noboot methods use a fast algorithm that works under the assumption of linearity and additivity of exposures (as described in the original paper on quantile-based g-computation). The \"standard\" method of g-computation with time-fixed exposures involves first fitting conditional models for the outcome, making predictions from those models under set exposure values, and then summarizing the predicted outcome distribution, possibly by fitting a second (marginal structural) model. qgcomp_*_boot follows this three-step process, while qgcomp_*_ee leverages estimating equations (sometimes: M-estimation) to estimate the parameters of the conditional and marginal structural model simultaneously. qgcomp_*_ee uses a sandwich variance estimator, which is similar to GEE (generalized estimating equation) approaches, and thus, when used correctly, can yield inference for longitudinal data in the same way that GEE does. The bootstrapping approach can also do this, but it takes longer. The extension to longitudinal data is representative of the broader concept that qgcomp_*_boot and qgcomp_*_ee can be used in a broader number of settings than qgcomp_*_noboot algorithms, but if one assumes linearity and additivity with no clustering of observations, and conditional parameters are of interest, then they are just a slower way to get equivalent results to qgcomp_*_noboot.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Below, we demonstrate a non-linear conditional fit (with a linear MSM) using the bootstrap approach. Similar approaches could be used to include interaction terms between exposures, as well as between exposures and covariates. Note this example is purposefully done incorrectly, as explained below.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"# create a formula with all polynomial terms for expsosure programatically by:\n# 1: outcome term\nlhs = GLM.Term(:y)\n# 2: main terms for all exposures\nmain_terms = GLM.Term.(Symbol.(Xnm))\n# 3: create squared terms for all exposures via a custom function\nfunction powerterm(x::S,power::I) where {S<:AbstractString, I<:Int}\n    FunctionTerm(^, [Term(Symbol(x)),ConstantTerm(power)], Expr(:call, :^, Symbol(x), power))\nend\nsquared_terms = powerterm.(Xnm, 2)\n\n# use ... \"splatting\" to combine all terms into a tuple\nrhs = (vcat(main_terms, squared_terms)...,)\n\nffsq = FormulaTerm(lhs, rhs) # this is a shorthand way of constructing the same object you would get from  @formula(y~ x1 + x1^2 + x2 + x2^2 + ...)\n\n\nqcboot_fit4 = qgcomp_glm_boot(rng, ffsq, metals, Xnm, 4, Normal(), B=100) \nprintln(qcboot_fit4)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"responseplot(qcboot_fit4, plots=[\"pointwise\", \"model\"]) ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Note that allowing for a non-linear effect of all exposures induces an apparent non-linear trend in the overall exposure effect. The smoothed regression line is  still well within the confidence bands of the marginal linear model  (by default, the overall effect of joint exposure is assumed linear,  though this assumption can be relaxed via the \"degree\" parameter in qgcompglmboot or qgcompglmee,  as follows:","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"\nqcboot_fit5 = qgcomp_glm_boot(Xoshiro(122),ffsq, metals, Xnm, 4, Normal(), msmformula = @formula(y~mixture+mixture^2)) # directly specify MSM formula\nresponseplot(qcboot_fit5) ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"qcee_fit5b = qgcomp_glm_ee(ffsq, metals, Xnm, 4, Normal(), msmformula = @formula(y~mixture+mixture^2)) #Using estimating equations\nresponseplot(qcee_fit5b) ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Note that some features are not availble to qgcomp_*_ee methods, which use estimating equations, rather than maximum likelihood methods. Briefly, these allow assessment of uncertainty under n-lin (and other) scenarios where the qgcomp_*_noboot functions cannot, since they rely on the additivity and linearity assumptions to achieve speed. The qgcomp_*_ee methods will generally be faster than a bootstrapped version, but they are not used extensively here because they are the newest additions to the qgcomp package, and the bootstrapped versions can be made fast (but not accurate) by reducing the number of bootstraps. Where available, the qgcomp_*_ee will be preferred to the qgcomp_*_boot versions for more stable and faster analyses when bootstrapping would otherwise be necessary.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Once again, we can access numerical estimates of uncertainty (answers differ between the qgcomp_*_boot and qgcomp_*_ee fits due to the small number of bootstrap samples):","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"# not yet implemented\nprintbounds(bounds(qcboot_fit5))","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"printbounds(bounds(qcee_fit5b))","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Ideally, the smooth fit will look very similar to the model prediction regression  line.","category":"page"},{"location":"glm/#Interpretation-of-model-parameters","page":"Generalized Linear Models","title":"Interpretation of model parameters","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"As the output below shows, setting \"degree=2\" yields a second parameter in the model fit (psi_2 or mixture^2). The output of qgcomp now corresponds to estimates of the marginal structural model given by ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"mathbbEleft(Y^mathbfX_qright) = g(psi_0 + psi_1 S_q + psi_2 S_q^2)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"println(qcboot_fit5)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"so that psi_2 can be interpreted similar to quadratic terms that might appear in a generalized linear model. psi_2 estimates the change in the outcome for an additional unit of squared joint exposure, over-and-above the linear effect given by psi_1. Informally, this is a way of assessing specific types of non-linearity in the joint exposure-response curves, and there are many other (slightly incorrect but intuitively useful) ways of interpreting parameters for squared terms in regressions (beyond the scope of this document). Intuition from generalized linear models (i.e. regarding interpretation of coefficients) applies directly to the models fit by quantile g-computation.","category":"page"},{"location":"glm/#Example-5:-comparing-model-fits-and-further-exploring-non-linearity","page":"Generalized Linear Models","title":"Example 5: comparing model fits and further exploring non-linearity","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Exploring a non-linear fit in settings with multiple exposures is challenging. One way to explore non-linearity, as demonstrated above, is to to include all 2-way interaction terms (including quadratic terms, or \"self-interactions\"). Sometimes this approach is not desired, either because the number of terms in the model can become very large, or because some sort of model selection procedure is required, which risks inducing over-fit (biased estimates and standard errors that are too small). Short of having a set of a priori non-linear terms to include, we find it best to take a default approach (e.g. taking all second order terms) that doesn't rely on statistical significance, or to simply be honest that the search for a non-linear model is exploratory and shouldn't be relied upon for robust inference. Methods such as kernel machine regression may be good alternatives, or supplementary approaches to exploring non-linearity.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"NOTE: qgcomp necessarily fits a regression model with exposures that have a small number of possible values, based on the quantile chosen. By package default, this is q=4, but it is difficult to fully examine non-linear fits using only four points, so we recommend exploring larger values of q, which will change effect estimates (i.e. the model coefficient implies a smaller change in exposures, so the expected change in the outcome will also decrease).","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Here, we examine a one strategy for default and exploratory approaches to mixtures that can be implemented in qgcomp using a smaller subset of exposures (iron, lead, cadmium), which we choose via the correlation matrix. High correlations between exposures may result from a common source, so small subsets of the mixture may be useful for examining hypotheses that relate to interventions on a common environmental source or set of behaviors. We can still adjust for the measured exposures, even though only 3 our exposures of interest are considered as the mixture of interest. First, we will demonstrate a linear MSM fit. Note that qgcomp_glm_boot must be used in order to produce the graphics below, as qgcomp_glm_noboot does not calculate the necessary quantities.","category":"page"},{"location":"glm/#Graphical-approach-to-explore-non-linearity-in-a-correlated-subset-of-exposures-using-splines","page":"Generalized Linear Models","title":"Graphical approach to explore non-linearity in a correlated subset of exposures using splines","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"newXnm = [:iron, :lead, :cadmium]\n\nqc_fit6lin = qgcomp_glm_boot(Xoshiro(122),@formula(y ~ iron + lead + cadmium + \n                         mage35 + arsenic + magnesium + manganese + mercury + \n                         selenium + silver + sodium + zinc),\n                        metals, newXnm,\n                          8, Normal(), B=100)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"This next model will require a different way to specify the model formula to help in exploring non-linearity via splines. The @formula macro in Julia does not allow splines to be specified in this way. The rcs function uses a restricted cubic spline function that is similar to the splines used in the Hmisc package (in R) and %DASPLINE macro (in SAS). Here, we have to explicitly specify knots, though there are helper functions to calculate knots based on the same defaults as Hmisc.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Note that thse spline bases are done on the \"quantized\" exposures (a categories).","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"# getting quantiles of \"quantized\" versions for knots of restricted cubic splines\nknts_iron = quantile(quantize(metals.iron, 8)[1], [0.05, 0.275, 0.5, 0.725, 0.95])\nknts_cadmium = quantile(quantize(metals.cadmium, 8)[1], [0.05, 0.275, 0.5, 0.725, 0.95])\n#knts_lead = quantile(quantize(metals.lead, 8)[1], [0.05, 0.275, 0.5, 0.725, 0.95])\nknts_lead = rsplineknots(quantize(metals.lead)[1], 5)\n#equivalent: rsplineknots(quantize(metals.lead)[1], 5)\n\nform_spline_nonlin = term(:y) ~ term(1) + rcs(:iron, knts_iron) + rcs(:cadmium, knts_cadmium) + rcs(:lead, knts_lead) + sum([term(Symbol(t)) for t in [\"mage35\", \"arsenic\", \"magnesium\", \"manganese\", \"mercury\", \"selenium\", \"silver\", \"sodium\", \"zinc\"]]) \n\n                          \n\nqc_fit6nonlin = qgcomp_glm_boot(Xoshiro(122),form_spline_nonlin,\n                         metals, newXnm, 8, Normal(), B=100, degree=2)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"We can also elaborate on this model using further spline terms by including interactions (recalling that this will lead to non-linearity in the overall effect). This model is for easy illustration only - it is likely grossly overfit, but it demonstrates different ways to allow non-linearty and non-addivity in a flexible way (here we use the estimating equation approach for illustration - it could also be a bootstrap fit)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"\nform_spline_nonlin_nonint = term(:y) ~ term(1) + rcs(:iron, knts_iron)* rcs(:cadmium, knts_iron) + rcs(:lead, knts_lead) + sum([term(Symbol(t)) for t in [\"mage35\", \"arsenic\", \"magnesium\", \"manganese\", \"mercury\", \"selenium\", \"silver\", \"sodium\", \"zinc\"]]) \n\nqc_fit6nonlin_nonint = qgcomp_glm_ee(form_spline_nonlin_nonint,\n                         metals, newXnm, 8, Normal(), degree=2)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"It helps to place the plots on a common y-axis, which is easy due to dependence of the qgcomp plotting functions on ggplot. Here are the two fits :","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"p = plot( ylim=(-0.75, .75));\nresponseplot!(p, qc_fit6lin, referentindex = 4, plots=[\"model\"]);\nresponseplot!(p, qc_fit6nonlin, referentindex = 4, plots=[\"model\"])","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Here's the fit with interactions :","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"p = plot( ylim=(-0.75, .75));\nresponseplot!(p, qc_fit6nonlin_nonint, referentindex = 4)","category":"page"},{"location":"glm/#Caution-about-graphical-approaches","page":"Generalized Linear Models","title":"Caution about graphical approaches","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"The underlying conditional model fit can be made extremely flexible, and the graphical representation of this (via the  smooth conditional fit) can look extremely flexible. Simply matching the overall (MSM) fit to this line is not a viable strategy for identifying parsimonious models because that would ignore potential for overfit. Thus, caution should be used when judging the accuracy of a fit when comparing the \"smooth conditional fit\" to the  \"MSM fit.\" ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"\nform_spline_overfit = term(:y) ~ term(1) + \nrcs(:iron, rsplineknots(quantize(metals.iron)[1], 5))+\n rcs(:cadmium, rsplineknots(quantize(metals.cadmium)[1], 5)) + \n rcs(:lead, rsplineknots(quantize(metals.lead)[1], 5)) + \n rcs(:arsenic, rsplineknots(quantize(metals.arsenic)[1], 5)) + \n rcs(:magnesium, rsplineknots(quantize(metals.magnesium)[1], 5)) + \n rcs(:manganese, rsplineknots(quantize(metals.manganese)[1], 5)) + \n rcs(:mercury, rsplineknots(quantize(metals.mercury)[1], 5)) + \n rcs(:selenium, rsplineknots(quantize(metals.selenium)[1], 5)) + \n rcs(:sodium, rsplineknots(quantize(metals.sodium)[1], 5)) + \n rcs(:selenium, rsplineknots(quantize(metals.selenium)[1], 5)) + \n rcs(:zinc, rsplineknots(quantize(metals.zinc)[1], 5)) + \n term(:mage35)\n \n\nqc_overfit = qgcomp_glm_boot(Xoshiro(122),form_spline_overfit,\n                         metals, newXnm, 8, Normal(), B=100, degree=2)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"responseplot(qc_overfit, referentindex = 5)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Here, there is little statistical evidence for even a linear trend, which makes the  smoothed conditional fit appear to be overfit. The smooth conditional fit can be turned off, as below.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"responseplot(qc_overfit, referentindex = 5, plots=[\"pointwise\", \"model\"])","category":"page"},{"location":"glm/#Example-6:-miscellaneous-other-ways-to-allow-non-linearity","page":"Generalized Linear Models","title":"Example 6: miscellaneous other ways to allow non-linearity","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Note that these are included as examples of how to include non-linearities, and are not intended as  a demonstration of appropriate model selection. In fact, qc_fit7b is generally a bad idea in small to moderate sample sizes due to large numbers of parameters. ","category":"page"},{"location":"glm/#using-indicator-terms-for-each-quantile","page":"Generalized Linear Models","title":"using indicator terms for each quantile","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"The quantile scores of the exposures can be turned into indicator variables, rather than treated as a linear/continuous term. This requires using the \"contrasts\" keyword with DummyCoding() (similar to defining as a factor variable in R).","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"qc_fit7a = qgcomp_glm_boot(Xoshiro(122),@formula(y ~ iron + lead + cadmium + \n                         mage35 + arsenic + magnesium + manganese + mercury + \n                         selenium + silver + sodium + zinc),\n                         metals, newXnm, 8,\n                         Normal(), B=100,\n                         msmformula = @formula(y~mixture + mixture^2),\n                         contrasts = Dict(:iron => DummyCoding()))\n# underlying fit\nprintln(qc_fit7a.ulfit)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"responseplot(qc_fit7a)","category":"page"},{"location":"glm/#interactions-between-indicator-terms","page":"Generalized Linear Models","title":"interactions between indicator terms","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"The indicator variables can be given a set of product terms.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"qc_fit7b = qgcomp_glm_boot(Xoshiro(122),@formula(y ~ iron*lead + cadmium + \n                         mage35 + arsenic + magnesium + manganese + mercury + \n                         selenium + silver + sodium + zinc),\n                         metals, newXnm, 8,\n                         Normal(), B=200,\n                         msmformula = @formula(y~mixture + mixture^2),\n                         contrasts = Dict(\n                          :iron => DummyCoding(),\n                          #:lead => DummyCoding()\n                          )\n                          )","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"responseplot(qc_fit7b, plots=[\"p\", \"m\"])","category":"page"},{"location":"glm/#breaks-at-specific-quantiles-(these-breaks-act-on-the-quantized-basis)","page":"Generalized Linear Models","title":"breaks at specific quantiles (these breaks act on the quantized basis)","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"qc_fit7c = qgcomp_glm_boot(Xoshiro(122),@formula(y ~ (iron>4)*(lead>4) + cadmium + \n                         mage35 + arsenic + magnesium + manganese + mercury + \n                         selenium + silver + sodium + zinc),\n                         metals, newXnm, 8,\n                         Normal(), B=100,\n                         msmformula = @formula(y~mixture + mixture^2),\n)\n# underlying fit\nqc_fit7c.ulfit","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"responseplot(qc_fit7c)","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Note one restriction on exploring non-linearity: while we can use flexible functions such as splines for individual exposures, the overall fit is limited via the degree parameter to polynomial functions (here a quadratic polynomial fits the non-linear model well, and a cubic polynomial fits the non-linear/non-homogeneous model well - though this is an informal argument and does not account for the wide confidence intervals). We note here that only 10 bootstrap iterations are used to calculate confidence intervals (to increase computational speed for the example), which is far too low.","category":"page"},{"location":"glm/#Statistical-approach-explore-non-linearity-in-a-correlated-subset-of-exposures-using-splines","page":"Generalized Linear Models","title":"Statistical approach explore non-linearity in a correlated subset of exposures using splines","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"The graphical approaches don't give a clear picture of which model might be preferred, but we can compare the model fits using AIC, or BIC (information criterion that weigh model fit with over-parameterization). Both of these criterion suggest the linear model fits best (lowest AIC and BIC), which suggests that the apparently non-linear fits observed in the graphical approaches don't improve prediction of the health outcome, relative to the linear fit, due to the increase in variance associated with including more parameters.","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"println(aic(qc_fit6lin))\n#aic(qc_fit6nonlin) |> display\n#aic(qc_fit6nonhom) |> display\n","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"println(bic(qc_fit6lin))\n#bic(qc_fit6nonlin) |> display\n#bic(qc_fit6nonhom) |> display","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"More examples on advanced topics can be viewed in the other package vignette.","category":"page"},{"location":"glm/#FAQ","page":"Generalized Linear Models","title":"FAQ","text":"","category":"section"},{"location":"glm/#Why-don't-I-get-weights/scaled-effects-from-the-boot-or-ee-functions?-(and-other-questions-about-the-weights/scaled-effect-sizes)","page":"Generalized Linear Models","title":"Why don't I get weights/scaled effects from the boot or ee functions? (and other questions about the weights/scaled effect sizes)","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Users often use the qgcomp_*_boot or qgcomp_*_ee functions because they want to marginalize over confounders or fit a non-linear joint exposure function. In both cases, the overall exposure response will no longer correspond to a simple weighted average of model coefficients, so none of the qgcomp_*_boot or qgcomp_*_ee functions will calculate weights. In most use cases, the weights would vary according to which level of joint exposure you\"re at, so it is not a straightforward proposition to calculate them (and you may not wish to report 4 sets of weights if you use the default q=4). That is, the contribution of each exposure to the overall effect will change across levels of exposure if there is any non-linearity, which makes the weights not useful as simple inferential tools (and, at best, an approximation). If you wish to have an approximation, then use a \"noboot\" method and report the weights from that along with a caveat that they are not directly applicable to the results in which non-linearity/non-additivity/marginalization-over-covariates is performed (using boot methods). If you fit an otherwise linear model, you can get weights from a qgcomp_*_noboot which will be very close to the weights you might get from a linear model fit via qgcomp_*_boot functions, but be explicit that the weights come from a different model than the inference about joint exposure effects. ","category":"page"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"It should be emphasized here that the weights are not a stable or entirely useful quantity for many research goals. Qgcomp addresses the mixtures problem of variance inflation by focusing on a parameter that is less susceptible to variance inflation than independent effects (the psi parameters, or overall effects of a mixture). The weights are a form of independent effect and will always be sensitive to this issue, regardless of the statistical method that is used. Some statistical approaches to improving estimation of independent effects (e.g. setting bayes=TRUE, R package only) is accessible in many qgcomp functions, but these approaches universally introduce bias in exchange for reducing variance and shouldn't be used without a good understanding of what shrinkage and penalization methods actually accomplish. Principled and rigorous integration of these statistical approaches with qgcomp is in progress, but that work is inherently more bespoke and likely will not be available in this R package. The shrinkage and penalization literature is large and outside the scope of this software and documentation, so no other guidance is given here. In any case, the calculated weights are only interpretable as proportional effect sizes in a setting in which there is linearity, additivity, and collapsibility, and so the package makes no efforts to try to introduce weights into other settings in which those assumptions may not be met. Outside of those narrow settings, the weights would have a dubious interpretation and the programming underlying the qgcomp package errs on the side of preventing the reporting of results that are mutually inconsistent. If you are using the boot versions of a qgcomp function in a setting in which you know that the weights are valid, it is very likely that you do not actually need to be using the boot versions of the functions.","category":"page"},{"location":"glm/#Do-I-need-to-model-non-linearity-and-non-additivity-of-exposures?","page":"Generalized Linear Models","title":"Do I need to model non-linearity and non-additivity of exposures?","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Maybe. The inferential object of qgcomp is the set of psi parameters that correspond to a joint exposure response. As it turns out, with correlated exposures non-linearity can disguise itself as non-additivity (Belzak and Bauer [2019] Addictive Behaviors). If we were inferring independent effects, this distinction would be crucial, but for joint effects it may turn out that it doesn't matter much if you model non-linearity in the joint response function through non-additivity or non-linearity of individual exposures in a given study. Models fit in qgcomp still make the crucial assumption that you are able to model the joint exposure response via parametric models, so that assumption should not be forgotten in an effort to try to disentagle non-linearity (e.g. quadratic terms of exposures) from non-additivity (e.g. product terms between exposures). The important part to note about parametric modeling is that we have to explicitly tell the model to be non-linear, and no adaptation to non-linear settings will happen automatically. Exploring non-linearity is not a trivial endeavor.","category":"page"},{"location":"glm/#Do-I-have-to-use-quantiles?","page":"Generalized Linear Models","title":"Do I have to use quantiles?","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"No. You can turn off \"quantization\" by setting q=nothing or you can supply your own categorization cutpoints via the \"breaks\" argument. It is up to the user to interpret the results if either of these options is taken. Frequently, q=nothing is used in concert with standardizing exposure variables by dividing them by their interquartile ranges (IQR). The joint exposure response can then be interpreted as the effect of an IQR change in all exposures. Using IQR/2 (with or without a log transformation before hand) will yield results that are most (roughly) compatible with the package defaults (q=4) but that does not require quantization. Quantized variables have nice properties: they prevent extrapolation and reduce influence of outliers, but the choice of how to include exposures in the model should be a deliberate and well-informed one. There are examples of setting q=nothing in the help files for qgcompglmboot and qgcompglmee, but this approach is available for any of the qgcomp methods (and is accomplished nearly 100% outside of the package functions, aside from setting q=nothing).","category":"page"},{"location":"glm/#Can-I-cite-this-document?","page":"Generalized Linear Models","title":"Can I cite this document?","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"Probably not in a scientific manuscript. If you find an idea here that is not published anywhere else and wish to develop it into a full manuscript, feel free! (But probably check with alex.keil@nih.gov to ask if a paper is already in development or is, perhaps, already published.)","category":"page"},{"location":"glm/#Where-else-can-I-get-help?","page":"Generalized Linear Models","title":"Where else can I get help?","text":"","category":"section"},{"location":"glm/","page":"Generalized Linear Models","title":"Generalized Linear Models","text":"The vignettes of the package and the help files of the functions give many, many examples of usage. Additionally, some edge case or interesting applicationsare available in the form of github gists at https://gist.github.com/alexpkeil1. If you come up with an interesting problem that you think could be solved in this package, but is currently not, feel free to submit an issue on the R package github page https://github.com/alexpkeil1/qgcomp/issues or J package github page https://github.com/alexpkeil1/Qgcomp.jl/issues. Several additions to the R package have already come about through that avenue (though not always quickly).","category":"page"},{"location":"#Index-of-functions","page":"Help","title":"Index of functions","text":"","category":"section"},{"location":"","page":"Help","title":"Help","text":"","category":"page"},{"location":"#Function-help","page":"Help","title":"Function help","text":"","category":"section"},{"location":"#Qgcomp.apply_mixture_msm_baseline-Union{Tuple{M}, Tuple{Any, M, Any}} where M<:NamedTuple","page":"Help","title":"Qgcomp.apply_mixture_msm_baseline","text":"Create a dataset used in a marginal structural model will all values of  mixture set to a specific value and covariates (if any) set to reference values. \n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.bounds","page":"Help","title":"Qgcomp.bounds","text":"Confidence bounds for effect measures and linear predictions at joint exposure values\n\nusing Qgcomp, DataFrames, StatsModels\n\nx1 = rand(100, 3)\nx = rand(100, 3)\nz = rand(100, 3)\nxq, _ = Qgcomp.get_xq(x, 4)\ny = randn(100) + xq * [.1, 0.05, 0]\ndata = DataFrame(hcat(y,x,z), [:y, :x1, :x2, :x3, :z1, :z2, :z3])\nform = @formula(y~x1+x2+x3+z1+z2+z3)\nform_noint = @formula(y~ -1+x1+x2+x3+z1+z2+z3)\nexpnms = [:x1, :x2, :x3]\n\nm = qgcomp_glm_ee(form, data, expnms, 4, Normal())\nQgcomp.printbounds(bounds(m, 0:0.1:3, 0.8))\n\n\n\n\n\n","category":"function"},{"location":"#Qgcomp.bspline-Tuple{Any, Any}","page":"Help","title":"Qgcomp.bspline","text":"bsplineIntknts(0,5, 8)\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.bsplineZeroBasis-Tuple{Number, Vector{<:Number}}","page":"Help","title":"Qgcomp.bsplineZeroBasis","text":"bsplineZeroBasis([0.0,0.3,3.0],0.1, 2.0)\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.bsplineknots-Tuple{Any, Any, Any}","page":"Help","title":"Qgcomp.bsplineknots","text":"bsplineknots(0,5, 8)   extdist = determines the distance between external knots. Set to 0 for classic \"repeated\" tail knots.             if positive, a constant gap between exterior knots starting at max value + epsilonilon             if negative, a constant multiplier of the final gap size between interior knots\n\nusing Qgcomp, DataFrames, Distributions, StatsModels\n\nn = 200\ndat = DataFrame(y=Int.(rand(Bernoulli(0.25), n)), x1=rand(n), x2=rand(n), z=rand(n))\n\n# 3 internal knots\ndeg = 2\nknts = bsplineknots(dat.x1, 5, deg; ptype = \"uniform\", extdist = 1)\nnkn = length(knts)\nnkn - deg \nsize(bs(dat.x1,knts), 2)\n\n\nkform = term(:y) ~ term(1) + bs(:x1,knts) + term(:x2)\nft = qgcomp_glm_ee(kform, dat,[:x1, :x2], nothing, Normal())\nft = qgcomp_glm_boot(kform, dat,[:x1, :x2], nothing, Normal())\n\n\nusing GLM\nglm(kform, dat, Binomial())\n\n\n\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.qgcomp_cox_boot-NTuple{5, Any}","page":"Help","title":"Qgcomp.qgcomp_cox_boot","text":"using Qgcomp\nusing LSurvival, DataFrames, Random\nrng = MersenneTwister()\n# expected effect size in qgcomp for X1, X2  (truebeta[1] + truebeta[2])/4 = 0.5\ntruebeta = [4.0, -2.0, 1.0, -1.0, 1.0]\napproxpsi = (truebeta[1] + truebeta[2])/4\nX, t, d = LSurvival.dgm_phmodel(300; =1.25,=truebeta)\nsurvdata = hcat(DataFrame(X, [:x1, :x2, :z1, :z2, :z3]), DataFrame(hcat(t,d),[:t,:d]))\n\nrng = Xoshiro(1232)\n\n# conditional MSM with fast estimator\nqgcomp_cox_noboot(rng, @formula(Surv(t, d)~x1+x2+z1+z2+z3), survdata, [\"x1\", \"x2\"], 4)\n\n# conditional MSM with traditional g-computation estimator (conditional on covariates - should look a lot like the \"noboot\" version)\nqgcomp_cox_boot(rng, @formula(Surv(t, d)~x1+x2+z1+z2+z3), survdata, [\"x1\", \"x2\"], 4, msmformula=@formula(Surv(t, d)~mixture+z1+z2+z3))\n\n# population MSM with traditional g-computation estimator (necessary, in this case)\nqgcomp_cox_boot(rng, @formula(Surv(t, d)~x1+x2+z1+z2+z3), survdata, [\"x1\", \"x2\"], 4, msmformula=@formula(Surv(t, d)~mixture+z1+z2+z3))\n\n# non-linear MSM with traditional g-computation estimator (necessary, in this case)\nqgcomp_cox_boot(rng, @formula(Surv(t, d)~x1+x2+x1*x2+z1+z2+z3), survdata, [\"x1\", \"x2\"], 4, msmformula=@formula(Surv(t, d)~mixture+mixture^2))\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.qgcomp_cox_noboot-NTuple{4, Any}","page":"Help","title":"Qgcomp.qgcomp_cox_noboot","text":"using Qgcomp\nusing LSurvival, DataFrames, Random\nid, int, out, data = LSurvival.dgm(MersenneTwister(1212), 100, 20);\n\ndata[:, 1] = round.(data[:, 1], digits = 3);\nd, X = data[:, 4], data[:, 1:3];\nwt = ones(length(d)) # random weights just to demonstrate usage\ntab = ( in = int, out = out, d=d, x=X[:,1], z1=X[:,2], z2=X[:,3]) ;\ndf = DataFrame(tab)\n\ncoxph(@formula(Surv(in, out, d)~x+z1+z2), tab, ties = \"efron\", wts = wt) |> display\nm = qgcomp_cox_noboot(@formula(Surv(in, out, d)~x+z1+z2), df, [\"z1\", \"z2\"], 4)\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.qgcomp_glm_boot-NTuple{6, Any}","page":"Help","title":"Qgcomp.qgcomp_glm_boot","text":"using Qgcomp, DataFrames, StatsModels, StatsBase\n\nx1 = rand(100, 3)\nx = rand(100, 3)\nz = rand(100, 3)\nxq, _ = Qgcomp.get_xq(x, 4)\ny = randn(100) + xq * [.1, 0.05, 0]+ (xq .* xq) * [-.1, 0.05, 0]\nybin = Int.(y .> median(y))\ndata = DataFrame(hcat(ybin,y,x,z), [:ybin, :y, :x1, :x2, :x3, :z1, :z2, :z3])\nform = @formula(y~x1+x2+x3+x1^2+x2^2+x3^2+z1+z2+z3)\nformbin = @formula(ybin~x1+x2+x3+x1^2+x2^2+x3^2+z1+z2+z3)\nexpnms = [:x1, :x2, :x3]\n\n# note the top fit is incorrect\nm0 = qgcomp_glm_noboot(form, data, expnms, 4, Normal()) \n\n# three ways to specify non-linear fits\nm = qgcomp_glm_boot(form, data, expnms, 4, Normal(), B=2000, msmformula=@formula(y~mixture+mixture^2)) \nmb = qgcomp_glm_boot(form, data, expnms, 4, Normal(), B=2000, degree=2) \nm2 = qgcomp_glm_ee(form, data, expnms, 4, Normal(), degree=2) \nisfitted(m)\nfitted(m)\naic(m)\naicc(m)\nbic(m)\nloglikelihood(m)\n\n# binary outcome\n# note the top fit is incorrect\nm0 = qgcomp_glm_noboot(formbin, data, expnms, 4, Bernoulli()) \n\n# three ways to specify non-linear fits\nm = qgcomp_glm_boot(formbin, data, expnms, 4, Binomial(), B=2000, msmformula=@formula(y~mixture+mixture^2)) \nmb = qgcomp_glm_boot(formbin, data, expnms, 4, Binomial(), B=2000, degree=2) \nm2 = qgcomp_glm_ee(formbin, data, expnms2, 4, Binomial(), degree=2) \n\n\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.qgcomp_glm_ee-NTuple{5, Any}","page":"Help","title":"Qgcomp.qgcomp_glm_ee","text":"binary\n\ndat = DataFrame(y=Int.(rand(Bernoulli(0.25), 50)), x1=rand(50), x2=rand(50), z=rand(50))\n\n# Marginal mixture OR (no confounders)\nft1 = qgcomp_glm_noboot(@formula(y ~ x1 + x2), dat,[\"x1\", \"x2\"], nothing, Binomial())\nft2 = qgcomp_glm_ee(@formula(y ~ x1 + x2), dat,[\"x1\", \"x2\"], nothing, Binomial())\nft3 = qgcomp_glm_ee(@formula(y ~ x1 + x2), dat,[\"x1\", \"x2\"], nothing, Binomial(), rr=true)\n\n# Conditional mixture OR\nqgcomp_glm_noboot(@formula(y ~ z + x1 + x2), dat,[\"x1\", \"x2\"], 4, Binomial())\n# Marginal mixture OR\nqgcomp_glm_ee(@formula(y ~ z + x1 + x2), dat,[\"x1\", \"x2\"], 4, Binomial())\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.qgcomp_glm_noboot-NTuple{5, Any}","page":"Help","title":"Qgcomp.qgcomp_glm_noboot","text":"using Qgcomp, DataFrames, StatsModels\n\nx1 = rand(100, 3)\nx = rand(100, 3)\nz = rand(100, 3)\nxq, _ = Qgcomp.get_xq(x, 4)\ny = randn(100) + xq * [.1, 0.05, 0]\ndata = DataFrame(hcat(y,x,z), [:y, :x1, :x2, :x3, :z1, :z2, :z3])\nform = @formula(y~x1+x2+x3+z1+z2+z3)\nform_noint = @formula(y~-1+x1+x2+x3+z1+z2+z3)\nexpnms = [:x1, :x2, :x3]\n\nm = qgcomp_glm_noboot(form, data, expnms, 4, Normal())\nm = qgcomp_glm_noboot(form_noint, data, expnms, 4, Normal())\nfitted(m)\naic(m)\naicc(m)\nbic(m)\nloglikelihood(m)\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.quantize-Tuple{Vector, Any}","page":"Help","title":"Qgcomp.quantize","text":"x = rand(100, 3)\nq=4\nnexp = size(x,2)\n\nxq, breaks = quantize(x, q)\n\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.rsplineknots-Tuple{Any, Any}","page":"Help","title":"Qgcomp.rsplineknots","text":"Create a vector of restricted spline knots (based on rcspline.eval from R Hmisc package, normalized version)  usage: rsplineknots(x,nk)  x = vector of numbers  nk = number of (interior) knots  output: a nk-length vector of (interior) knots\n\n```julia  using Qgcomp, DataFrames, Distributions, StatsModels  dat = DataFrame(y=Int.(rand(Bernoulli(0.25), 50)), x1=rand(50), x2=rand(50), z=rand(50))\n\nknts = rsplineknots(dat.x1, 5)\n\nkform = term(:y)~ term(1) + rcs(:x1,knts) + term(:x2)  kform2 = term(:y)~ term(1) + rqs(:x1,knts) + term(:x2)\n\nft = qgcompglmee(kform, dat,[\"x1\", \"x2\"], nothing, Binomial())  ft = qgcompglmee(kform2, dat,[\"x1\", \"x2\"], nothing, Binomial())\n\n```\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.vccomb-Union{Tuple{R2}, Tuple{R1}, Tuple{R0}, Tuple{Matrix{R0}, Vector{R1}, Vector{R2}}} where {R0<:Real, R1<:Real, R2<:Real}","page":"Help","title":"Qgcomp.vccomb","text":"Covariance between linear combinations of terms\n\ne.g. for a linear regression  0 + 1x + 2z + 3w + 4r\n\nwith coefficient covariance matrix V, \n\nthe variance for  = 1 + 2 (e.g. the simultaneous effect of increasing x and z by one unit)     is calculated as vccomb(V, [0,1,1,0,0], [0,1,1,0,0])\n\nThe covariance term COV(, 0)      is calculated as vccomb(V, [0,1,1,0,0], [1,0,0,0,0])\n\nThis function is useful for qgcomp methods when  is just a sum of  coefficients, because it allows     straightforward calculation of the full covariance matrix. The underlying calculations are very simple,     but the function provides \n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.vccomb-Union{Tuple{S2}, Tuple{S1}, Tuple{R0}, Tuple{Matrix{R0}, Vector{S1}, Vector{S2}}} where {R0<:Real, S1<:String, S2<:String}","page":"Help","title":"Qgcomp.vccomb","text":"One version of the function (string vector arguments) is very specifically tuned toward a covariance matrix for qgcompglmboot,      given the covariance matrix column labels and expnms. It assumes a univariate  parameter.\n\n\n\n\n\n","category":"method"},{"location":"#RecipesBase.apply_recipe-Tuple{AbstractDict{Symbol, Any}, Qgcomp.ResponsePlot}","page":"Help","title":"RecipesBase.apply_recipe","text":"regression curve plot for msm\n\nusing Qgcomp\nusing Random, GLM, DataFrames, LSurvival\nusing Plots\n\n#using LinearAlgebra, StatsBase\npointwise = Qgcomp.pointwise\n#loesspred = Qgcomp.loesspred\nsmoothpred = Qgcomp.loesspred\n\nx1 = rand(100, 3)\nx = rand(100, 3)\nz = rand(100, 3)\nxq, _ = Qgcomp.get_xq(x, 4)\ny = randn(100) + xq .*  xq * [0.1, 0.05, 0]\nlindata = DataFrame(hcat(y, x, z), [:y, :x1, :x2, :x3, :z1, :z2, :z3])\n\nm = qgcomp_glm_boot(@formula(y~x1+x1^2+x2+x2^2+x3+x3^2+z1+z2+z3), lindata, [\"x1\", \"x2\", \"x3\", \"z1\"], 6, Normal(), msmformula=@formula(y~mixture+mixture^2))\n#x,y,ylower,yupper = pointwise(m.msm)\n\nresponseplot(m)\n\n# plots based on these bounds, except the smooth function\nbnds = bounds(m)\nmw = bnds[:model]\npw = bnds[:pointwise]\n\n\n\n\n\n\n\n","category":"method"},{"location":"#RecipesBase.apply_recipe-Tuple{AbstractDict{Symbol, Any}, Qgcomp.WeightPlot}","page":"Help","title":"RecipesBase.apply_recipe","text":"Plotting weights\n\nusing Qgcomp\nusing Random, GLM, DataFrames, LSurvival\nusing Plots\n\nx1 = rand(100, 3)\nx = rand(100, 3)\nz = rand(100, 3)\nxq, _ = Qgcomp.get_xq(x, 4)\ny = randn(100) + xq * [0.1, 0.05, 0]\nlindata = DataFrame(hcat(y, x, z), [:y, :x1, :x2, :x3, :z1, :z2, :z3])\n\nmint = qgcomp_glm_noboot(@formula(y~x1+x2+x3+z1+z2+z3), lindata, [\"x1\", \"x2\", \"x3\", \"z1\", \"z2\", \"z3\"], 4, Normal())\nweightplot(mint)\n\n\n\n\n\n","category":"method"},{"location":"#StatsAPI.fit!-Tuple{QGcomp_ee}","page":"Help","title":"StatsAPI.fit!","text":"n=300\nx = rand(n, 3)\nz = rand(n, 3)\nxq, _ = Qgcomp.get_xq(x, 4)\ny = randn(n) + xq * [.1, .05, 0]\ndata = DataFrame(hcat(y,x,z), [:y, :x1, :x2, :x3, :z1, :z2, :z3])\nform = @formula(y~x1+x2+x3+x3+z1+z2+z3)\nform2 = @formula(y~x1+x2+x3+x1^2+x2^2+x3^2+x1*z1+z2+z3)\nmsmformula = @formula(y~mixture+mixture^2)\nexpnms = [:x1, :x2, :x3]\nq = 4\nm = QGcomp_glm(form, data, expnms, 4, Normal());\nfit!(m)\nm2 = QGcomp_ee(form, data, expnms, 4, Normal());\nStatsBase.fit!(m2)\nm = QGcomp_ee(form, data, expnms, q, Normal())\nqgcomp_glm_noboot(form, data, expnms, 4, Normal())\nft = qgcomp_glm_ee(form2, data, expnms, q, Normal(),degree=2)\n\n\n\nkeys = Dict([\n    :msmformula => msmformula,\n])\ncontrasts = Dict{Symbol,Any}()\nrr = false\n\n\n\n\n\n\n\n","category":"method"},{"location":"#StatsAPI.fit!-Union{Tuple{M}, Tuple{Any, M}} where M<:Union{QGcomp_cox, QGcomp_glm}","page":"Help","title":"StatsAPI.fit!","text":"using Qgcomp, DataFrames, StatsModels\n\nx = rand(100, 3)\nz = rand(100, 3)\nxq, _ = Qgcomp.get_xq(x, 4)\ny = randn(100) + xq * [.1, .05, 0]\ndata = DataFrame(hcat(y,x,z), [:y, :x1, :x2, :x3, :z1, :z2, :z3])\nformula = @formula(y~x1+x2+x3+z1+z2+z3)\nexpnms = [\"x\"*string(i) for i in 1:3]\nm = Qgcomp.QGcomp_glm(formula, data, expnms, 4, Normal())\nm \nfit!(m)\nm \n\n\n\n\n\n","category":"method"},{"location":"#Implementation-details-and-further-help","page":"Help","title":"Implementation details and further help","text":"","category":"section"},{"location":"","page":"Help","title":"Help","text":"Pages = [\n    \"glm.md\"\n    ]\n    Depth = 4","category":"page"},{"location":"#References","page":"Help","title":"References","text":"","category":"section"},{"location":"","page":"Help","title":"Help","text":"Alexander P. Keil, Jessie P. Buckley, Katie M. O'Brien, Kelly K. Ferguson, Shanshan Zhao, Alexandra J. White. A quantile-based g-computation approach to addressing the effects of exposure mixtures. https://doi.org/10.1289/EHP5838 ","category":"page"},{"location":"math/underlying_math/#rules-of-variance:","page":"Underlying math","title":"rules of variance:","text":"","category":"section"},{"location":"math/underlying_math/#Variance-of-a-sum-of-random-variables","page":"Underlying math","title":"Variance of a sum of random variables","text":"","category":"section"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Var(X + Z) = var(X) + Var(Z) + Cov(XZ) + Cov(ZX)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Var(X - Z) = Var(X + -Z)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= Var(X) + Var(-Z) + Cov(X-Z) + Cov(-ZX)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= Var(X) + Var(Z) - Cov(XZ) - Cov(ZX)","category":"page"},{"location":"math/underlying_math/#Variance-of-a-sum-of-sums-of-random-variables","page":"Underlying math","title":"Variance of a sum of sums of random variables","text":"","category":"section"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"A=X+Z B=Y+W","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Var(A)= Var(X) + Var(Z) + 2*Cov(XZ)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Var(B)= Var(Y) + Var(W) + 2*Cov(YW)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Var(A+B)= Var(A) + Var(B) + 2*Cov(AB)","category":"page"},{"location":"math/underlying_math/#Variance-of-a-product-of-a-random-variable-and-a-constant","page":"Underlying math","title":"Variance of a product of a random variable and a constant","text":"","category":"section"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Var(X*c) = E(X*c-E(X*c))^2","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= E((X*c-cE(X))^2)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= E((X*c-cE(X))^2)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= E((c(X-E(X))^2)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= c^2 * E((X-E(X))^2)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= c^2 * Var(X)","category":"page"},{"location":"math/underlying_math/#Covariance-of-a-random-variable-and-a-product-of-a-random-variable-and-a-constant","page":"Underlying math","title":"Covariance of a random variable and a product of a random variable and a constant","text":"","category":"section"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Cov(X*c Z) = E(X*c-E(X*c))(Z-E(X)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= c*E(X-E(X))(Z-E(X)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= c * Cov(X Z)","category":"page"},{"location":"math/underlying_math/#Gneralized-linear-model-characteristics","page":"Underlying math","title":"Gneralized linear model characteristics","text":"","category":"section"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"E(g(y)x) = 0 + 1*x1 + 2*x2","category":"page"},{"location":"math/underlying_math/#Standard-error-of-a-linear-combination","page":"Underlying math","title":"Standard error of a linear combination","text":"","category":"section"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"RD = E(yx=1) - E(yx=0) \n= 0 + 1*1 + 2*1 - (0 + 1*0 + 2*0)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"=1 + 2","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Var(RD) = Var(1 + 2)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= Var(1) + Var(2) + 2*Cov(12)","category":"page"},{"location":"math/underlying_math/#Variance-of-a-prediction","page":"Underlying math","title":"Variance of a prediction","text":"","category":"section"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Define a prediction for a two exposure linear model as E(yx) = 0 + 1*x1 + 2*x2","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Var(E(yx)) = Var(0 + 1*x1 + 2*x2)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= Var(0 + 1*x1 + 2*x2)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= Var(0) + Var(1*x1) + Var(2*x2) + 2*Cov(01*x1) + 2*Cov(02*x2) + 2*Cov(1*x12*x2)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= Var(0) + x1^2*Var(1) + x2^2*Var(2) + 2*Cov(01)*x1 + 2*Cov(02)*x2 + 2*x1*Cov(12)*x2","category":"page"},{"location":"math/underlying_math/#Variance/covariance-matrix-for-a-vector-of-predictions","page":"Underlying math","title":"Variance/covariance matrix for a vector of predictions","text":"","category":"section"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"mathbf1 = (1 1  1)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"X1 = (x1_1 x1_2  x1_n)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"X2 = (x2_1 x2_2  x2_n)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"mathbfX = (mathbf1 X1 X2)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"mathbf = (0 1 2)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Vcov(E(ymathbfX)) = Vcov(0 + 1*X1 + 2*X2)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"Vcov(E(ymathbfX)) = Vcov(mathbfX)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= (mathbfX - EmathbfX)(mathbfX - EmathbfX)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= (mathbfX - EmathbfX)(mathbfX - EmathbfX)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"= mathbfXX - E(mathbfX)mathbfX  - mathbfXE(mathbfX) + E(mathbfX)*E(mathbfX)","category":"page"},{"location":"math/underlying_math/","page":"Underlying math","title":"Underlying math","text":"using GLM, Random, LinearAlgebra\n\nx = rand(100, 2)\ny = 0.1 .+ x * [1.0, 0.3] + randn(100)\n\nX = hcat(ones(length(y)), x)\n\nbetahat = inv(X'X)X'y\n\nft = fit(LinearModel, X, y)\n\n\n\n\n\nV = GLM.vcov(ft)\ndiag(X * V * X')\n\nX[1:1,:] * V * X[1:1,:]'\n","category":"page"}]
}
