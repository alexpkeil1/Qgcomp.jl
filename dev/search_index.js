var documenterSearchIndex = {"docs":
[{"location":"glm/#Introduction-(copied-directly-from-the-qgcomp-package-in-R,-basic-vignette):","page":"-","title":"Introduction (copied directly from the qgcomp package in R, basic vignette):","text":"","category":"section"},{"location":"glm/","page":"-","title":"-","text":"Qgcomp.jl is a module to implement g-computation for analyzing the effects of exposure mixtures. Quantile g-computation yields estimates of the effect of increasing all exposures by one quantile, simultaneously. This, it estimates a \"mixture effect\" useful in the study of exposure mixtures such as air pollution, diet, and water contamination.","category":"page"},{"location":"glm/","page":"-","title":"-","text":"Using terminology from methods developed for causal effect estimation, quantile  g-computation estimates the parameters of a marginal structural model that  characterizes the change in the expected potential outcome given a joint intervention on all exposures, possibly conditional on confounders. Under the assumptions of exchangeability, causal consistency, positivity, no interference, and correct model specification, this model yields a causal effect for an intervention on the mixture as a whole. While these assumptions may not be met exactly, they provide a useful road map for how to interpret the results of a qgcomp fit, and where efforts should be spent in terms of ensuring accurate model specification and selection of exposures that are sufficient to control co-pollutant confounding.","category":"page"},{"location":"glm/#The-model","page":"-","title":"The model","text":"","category":"section"},{"location":"glm/","page":"-","title":"-","text":"Say we have an outcome Y, some exposures mathbbX and possibly some other covariates (e.g. potential confounders) denoted by mathbbZ.","category":"page"},{"location":"glm/","page":"-","title":"-","text":"The basic model of quantile g-computation is a joint marginal structural model given by","category":"page"},{"location":"glm/","page":"-","title":"-","text":"$","category":"page"},{"location":"glm/","page":"-","title":"-","text":"\\mathbb{E}(Y^{\\mathbf{X}q} | \\mathbf{Z,\\psi,\\eta}) = g(\\psi0 + \\psi1 Sq +  \\mathbf{\\eta Z}) $","category":"page"},{"location":"glm/","page":"-","title":"-","text":"where g(cdot) is a link function in a generalized linear model (e.g. the inverse logit function in the case of a logistic model for the probability that Y=1), psi_0 is the model intercept, mathbfeta is a set of model coefficients for the covariates and S_q is an \"index\" that represents a joint value of exposures. Quantile g-computation (by default) transforms all exposures mathbfX into mathbfX_q, which are \"scores\" taking on discrete values 0,1,2,etc. representing a categorical \"bin\" of exposure. By default, there are four bins with evenly spaced quantile cutpoints for each exposure, so X_q=0 means that X was below the observed 25th percentile for that exposure. The index S_q represents all exposures being set to the same value (again, by default, discrete values 0,1,2,3). Thus, the parameter psi_1 quantifies the expected change in the outcome, given a one quantile increase in all exposures simultaneously, possibly adjusted for mathbfZ. ","category":"page"},{"location":"glm/","page":"-","title":"-","text":"There are nuances to this particular model form that are available in the qgcomp package which will be explored below. There exists one special case of quantile g-computation that leads to fast fitting: linear/additive exposure effects. Here we simulate \"pre-quantized\" data where the exposures X_1 X_2 X_3 can only take on values of 0,1,2,3 in equal proportions. The model underlying the outcomes is given by the linear regression:","category":"page"},{"location":"glm/","page":"-","title":"-","text":"$","category":"page"},{"location":"glm/","page":"-","title":"-","text":"\\mathbb{E}(Y | \\mathbf{X,\\beta}) = \\beta0 + \\beta1 X1 + \\beta2 X2  + \\beta3 X_3  $","category":"page"},{"location":"glm/","page":"-","title":"-","text":"with the true values of beta_0=0 beta_1 =025 beta_2 =-01 beta_3=005, and X_1 is strongly positively correlated with X_2 (rho=095) and negatively correlated with X_3 (rho=-03). In this simple setting, the parameter psi_1 will equal the sum of the beta coefficients (0.2). Here we see that qgcomp estimates a value very close to 0.2 (as we increase sample size, the estimated value will be expected to become increasingly close to 0.2).","category":"page"},{"location":"glm/","page":"-","title":"-","text":"using Qgcomp, DataFrames, Random, StatsBase, StatsModels\n\n# generate some data under a linear model with \"quantized\" exposures\n    rng = Xoshiro(1232)\n    n = 1000\n    x = rand(rng, n, 3)\n    xq, _ = Qgcomp.get_xq(x, 4)\n    props = (.95, 0.3)\n    ns = floor.(Int, n .* props)\n    xq[:,2] = vcat(xq[1:ns[1],1], sample(rng, xq[ns[1]+1:end,1], n-ns[1]))\n    xq[:,3] = 3 .- vcat(xq[1:ns[2],1], sample(rng, xq[ns[2]+1:end,1], n-ns[2]))\n    y = randn(rng, n) + xq * [0.25, -0.1, 0.05]\n    lindata = DataFrame(hcat(y, xq), [:y, :x1, :x2, :x3])\n\n    # check correlations\n    cor(xq)\n\n    # fit model\n    qgcomp_glm_noboot(@formula(y~x1+x2+x3), lindata, [\"x1\", \"x2\", \"x3\"], 4, Normal())\n","category":"page"},{"location":"glm/","page":"-","title":"-","text":"\njulia> cor(xq)\n       # fit model\n3×3 Matrix{Float64}:\n  1.0        0.949536  -0.28404\n  0.949536   1.0       -0.293409\n -0.28404   -0.293409   1.0\n\n \njulia> qgcomp_glm_noboot(@formula(y~x1+x2+x3), lindata, [\"x1\", \"x2\", \"x3\"], 4, Normal())\nNegative weights\n1×4 DataFrame\n Row │ exposure  coef       ψ_partial  weight  \n     │ String    Float64    Float64    Float64 \n─────┼─────────────────────────────────────────\n   1 │ x2        -0.183042  -0.183042      1.0\nPositive weights\n2×4 DataFrame\n Row │ exposure  coef       ψ_partial  weight   \n     │ String    Float64    Float64    Float64  \n─────┼──────────────────────────────────────────\n   1 │ x1        0.309828    0.370049  0.837262\n   2 │ x3        0.0602209   0.370049  0.162738\n─────────────────────────────────────────────────────────────────────────\n                 Coef.  Std. Error     z  Pr(>|z|)   Lower 95%  Upper 95%\n─────────────────────────────────────────────────────────────────────────\n(Intercept)  0.0495911   0.0802297  0.62    0.5365  -0.107656    0.206839\nψ            0.187007    0.0550767  3.40    0.0007   0.0790588   0.294956\n─────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"#Index-of-functions","page":"Index of functions","title":"Index of functions","text":"","category":"section"},{"location":"","page":"Index of functions","title":"Index of functions","text":"","category":"page"},{"location":"#Function-help","page":"Index of functions","title":"Function help","text":"","category":"section"},{"location":"#Qgcomp.qgcomp_cox_boot-NTuple{5, Any}","page":"Index of functions","title":"Qgcomp.qgcomp_cox_boot","text":"using Qgcomp\nusing LSurvival, DataFrames, Random\nrng = MersenneTwister()\n# expected effect size in qgcomp for X1, X2 ≈ (truebeta[1] + truebeta[2])/4 = 0.5\ntruebeta = [4.0, -2.0, 1.0, -1.0, 1.0]\napproxpsi = (truebeta[1] + truebeta[2])/4\nX, t, d = LSurvival.dgm_phmodel(300; λ=1.25,β=truebeta)\nsurvdata = hcat(DataFrame(X, [:x1, :x2, :z1, :z2, :z3]), DataFrame(hcat(t,d),[:t,:d]))\n\nrng = Xoshiro(1232)\n\n# conditional MSM with fast estimator\nqgcomp_cox_noboot(rng, @formula(Surv(t, d)~x1+x2+z1+z2+z3), survdata, [\"x1\", \"x2\"], 4)\n\n# conditional MSM with traditional g-computation estimator (conditional on covariates - should look a lot like the \"noboot\" version)\nqgcomp_cox_boot(rng, @formula(Surv(t, d)~x1+x2+z1+z2+z3), survdata, [\"x1\", \"x2\"], 4, msmformula=@formula(Surv(t, d)~mixture+z1+z2+z3))\n\n# population MSM with traditional g-computation estimator (necessary, in this case)\nqgcomp_cox_boot(rng, @formula(Surv(t, d)~x1+x2+z1+z2+z3), survdata, [\"x1\", \"x2\"], 4, msmformula=@formula(Surv(t, d)~mixture+z1+z2+z3))\n\n# non-linear MSM with traditional g-computation estimator (necessary, in this case)\nqgcomp_cox_boot(rng, @formula(Surv(t, d)~x1+x2+x1*x2+z1+z2+z3), survdata, [\"x1\", \"x2\"], 4, msmformula=@formula(Surv(t, d)~mixture+mixture^2))\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.qgcomp_cox_noboot-NTuple{4, Any}","page":"Index of functions","title":"Qgcomp.qgcomp_cox_noboot","text":"using Qgcomp\nusing LSurvival, DataFrames, Random\nid, int, out, data = LSurvival.dgm(MersenneTwister(1212), 100, 20);\n\ndata[:, 1] = round.(data[:, 1], digits = 3);\nd, X = data[:, 4], data[:, 1:3];\nwt = ones(length(d)) # random weights just to demonstrate usage\ntab = ( in = int, out = out, d=d, x=X[:,1], z1=X[:,2], z2=X[:,3]) ;\ndf = DataFrame(tab)\n\ncoxph(@formula(Surv(in, out, d)~x+z1+z2), tab, ties = \"efron\", wts = wt) |> display\nm = qgcomp_cox_noboot(@formula(Surv(in, out, d)~x+z1+z2), df, [\"z1\", \"z2\"], 4)\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.qgcomp_glm_boot-NTuple{5, Any}","page":"Index of functions","title":"Qgcomp.qgcomp_glm_boot","text":"using Qgcomp, DataFrames, StatsModels, StatsBase\n\nx1 = rand(100, 3)\nx = rand(100, 3)\nz = rand(100, 3)\nxq, _ = Qgcomp.get_xq(x, 4)\ny = randn(100) + xq * [.1, 0.05, 0]+ (xq .* xq) * [-.1, 0.05, 0]\nybin = Int.(y .> median(y))\ndata = DataFrame(hcat(ybin,y,x,z), [:ybin, :y, :x1, :x2, :x3, :z1, :z2, :z3])\nform = @formula(y~x1+x2+x3+x1^2+x2^2+x3^2+z1+z2+z3)\nformbin = @formula(ybin~x1+x2+x3+x1^2+x2^2+x3^2+z1+z2+z3)\nexpnms = [:x1, :x2, :x3]\n\n# note the top fit is incorrect\nm0 = qgcomp_glm_noboot(form, data, expnms, 4, Normal()) \n\n# three ways to specify non-linear fits\nm = qgcomp_glm_boot(form, data, expnms, 4, Normal(), B=2000, msmformula=@formula(y~mixture+mixture^2)) \nmb = qgcomp_glm_boot(form, data, expnms, 4, Normal(), B=2000, degree=2) \nm2 = qgcomp_glm_ee(form, data, expnms, 4, Normal(), degree=2) \nisfitted(m)\nfitted(m)\naic(m)\naicc(m)\nbic(m)\nloglikelihood(m)\n\n# binary outcome\n# note the top fit is incorrect\nm0 = qgcomp_glm_noboot(formbin, data, expnms, 4, Bernoulli()) \n\n# three ways to specify non-linear fits\nm = qgcomp_glm_boot(formbin, data, expnms, 4, Binomial(), B=2000, msmformula=@formula(y~mixture+mixture^2)) \nmb = qgcomp_glm_boot(formbin, data, expnms, 4, Binomial(), B=2000, degree=2) \nm2 = qgcomp_glm_ee(formbin, data, expnms2, 4, Binomial(), degree=2) \n\n\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.qgcomp_glm_ee-NTuple{5, Any}","page":"Index of functions","title":"Qgcomp.qgcomp_glm_ee","text":"binary\n\ndat = DataFrame(y=Int.(rand(Bernoulli(0.25), 50)), x1=rand(50), x2=rand(50), z=rand(50))\n\n# Marginal mixture OR (no confounders)\nft1 = qgcomp_glm_noboot(@formula(y ~ x1 + x2), dat,[\"x1\", \"x2\"], nothing, Binomial())\nft2 = qgcomp_glm_ee(@formula(y ~ x1 + x2), dat,[\"x1\", \"x2\"], nothing, Binomial())\nft3 = qgcomp_glm_ee(@formula(y ~ x1 + x2), dat,[\"x1\", \"x2\"], nothing, Binomial(), rr=true)\n\n# Conditional mixture OR\nqgcomp_glm_noboot(@formula(y ~ z + x1 + x2), dat,[\"x1\", \"x2\"], 4, Binomial())\n# Marginal mixture OR\nqgcomp_glm_ee(@formula(y ~ z + x1 + x2), dat,[\"x1\", \"x2\"], 4, Binomial())\n\n\n\n\n\n","category":"method"},{"location":"#Qgcomp.qgcomp_glm_noboot-NTuple{5, Any}","page":"Index of functions","title":"Qgcomp.qgcomp_glm_noboot","text":"using Qgcomp, DataFrames, StatsModels\n\nx1 = rand(100, 3)\nx = rand(100, 3)\nz = rand(100, 3)\nxq, _ = Qgcomp.get_xq(x, 4)\ny = randn(100) + xq * [.1, 0.05, 0]\ndata = DataFrame(hcat(y,x,z), [:y, :x1, :x2, :x3, :z1, :z2, :z3])\nform = @formula(y~x1+x2+x3+z1+z2+z3)\nform_noint = @formula(y~-1+x1+x2+x3+z1+z2+z3)\nexpnms = [:x1, :x2, :x3]\n\nm = qgcomp_glm_noboot(form, data, expnms, 4, Normal())\nm = qgcomp_glm_noboot(form_noint, data, expnms, 4, Normal())\nfitted(m)\naic(m)\naicc(m)\nbic(m)\nloglikelihood(m)\n\n\n\n\n\n","category":"method"},{"location":"#StatsAPI.fit!-Tuple{Any, Qgcomp.QGcomp_glm}","page":"Index of functions","title":"StatsAPI.fit!","text":"using Qgcomp, DataFrames, StatsModels\n\nx = rand(100, 3)\nz = rand(100, 3)\nxq, _ = Qgcomp.get_xq(x, 4)\ny = randn(100) + xq * [.1, .05, 0]\ndata = DataFrame(hcat(y,x,z), [:y, :x1, :x2, :x3, :z1, :z2, :z3])\nformula = @formula(y~x1+x2+x3+z1+z2+z3)\nexpnms = [\"x\"*string(i) for i in 1:3]\nm = Qgcomp.QGcomp_glm(formula, data, expnms, 4, Normal())\nm \nfit!(m)\nm \n\n\n\n\n\n","category":"method"},{"location":"#StatsAPI.fit!-Tuple{Qgcomp.QGcomp_ee}","page":"Index of functions","title":"StatsAPI.fit!","text":"n=300\nx = rand(n, 3)\nz = rand(n, 3)\nxq, _ = get_xq(x, 4)\ny = randn(n) + xq * [.1, .05, 0]\ndata = DataFrame(hcat(y,x,z), [:y, :x1, :x2, :x3, :z1, :z2, :z3])\nform = @formula(y~x1+x2+x3+x3+z1+z2+z3)\nform2 = @formula(y~x1+x2+x3+x1^2+x2^2+x3^2+x1*z1+z2+z3)\nexpnms = [:x1, :x2, :x3]\nq = 4\nm = QGcomp_glm(form, data, expnms, 4, Normal());\nfit!(m)\nm2 = QGcomp_ee(form, data, expnms, 4, Normal());\nStatsBase.fit!(m2)\nm = QGcomp_ee(form, data, expnms, q, Normal())\nqgcomp_glm_noboot(form, data, expnms, 4, Normal())\nft = qgcomp_glm_ee(form2, data, expnms, q, Normal(),degree=2)\n\n\n\n\n\n","category":"method"},{"location":"#Implementation-details-and-further-help","page":"Index of functions","title":"Implementation details and further help","text":"","category":"section"},{"location":"","page":"Index of functions","title":"Index of functions","text":"Pages = [\n    \"glm.md\"\n    ]\n    Depth = 3","category":"page"},{"location":"#References","page":"Index of functions","title":"References","text":"","category":"section"},{"location":"","page":"Index of functions","title":"Index of functions","text":"Alexander P. Keil, Jessie P. Buckley, Katie M. O'Brien, Kelly K. Ferguson, Shanshan Zhao, Alexandra J. White. A quantile-based g-computation approach to addressing the effects of exposure mixtures. https://doi.org/10.1289/EHP5838 ","category":"page"}]
}
